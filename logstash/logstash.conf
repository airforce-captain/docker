#-------数据输入段.---------
input {
        tcp{
                port => 5124
                codec => "json"
                type => "maillog"
        }
        tcp{
                port => 5125
                        codec => "json"
                        type => "httpd"
        }
}
#------数据处理段.----------
filter {

        if [type] == "httpd" {
        grok {
        remove_field   => [ "@version", "port","timestamp[1]","facility","httpversion","ident","auth","severity","program" ]
	patterns_dir   => "/etc/logstash/conf.d/patterns.d"
        match => {"message" => "%{COMBINEDAPACHELOG}"}
        }
        geoip {
                database => "/etc/logstash/conf.d/GeoLite2-City.mmdb"
                source => "clientip"
                add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
                add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
                remove_field => [ "[geoip][continent_code]","[geoip][postal_code]","[geoip][region_name]","[geoip][continent_code]","[geoip][country_code2]","[geoip][country_code3]"   ]
        }
        mutate {
                convert => [ "[geoip][coordinates]", "float"]
        }
        }

#process raw message to remove not need fields
if [program] =~ /^postfix\/(local|smtp|lmtp|).*$/ {
        grok {
            remove_field   => [ "@version", "port" ]
            patterns_dir   => "/etc/logstash/conf.d/patterns.d"
            match          => [ "message", "%{POSTFIX_SMTP}" ]
            tag_on_failure => [ "_grok_postfix_smtp_nomatch" ]
            add_tag        => [ "_grok_postfix_success" ]
        }
# process key-value data is it exists
    if [postfix_keyvalue_data] {
        kv {
            source       => "postfix_keyvalue_data"
            trim_value   => "<>,"
            prefix       => "postfix_"
            remove_field => [ "postfix_keyvalue_data" ]
        }

        # some post processing of key-value data
        if [postfix_client] {
            grok {
                patterns_dir   => "/etc/logstash/conf.d/patterns.d"
                match          => ["postfix_client", "%{POSTFIX_CLIENT_INFO}"]
                tag_on_failure => [ "_grok_kv_postfix_client_nomatch" ]
                remove_field   => [ "postfix_client" ]
            }
        }
        if [postfix_relay] {
            grok {
                patterns_dir   => "/etc/logstash/conf.d/patterns.d"
                match          => ["postfix_relay", "%{POSTFIX_RELAY_INFO}"]
                tag_on_failure => [ "_grok_kv_postfix_relay_nomatch" ]
                remove_field   => [ "postfix_relay" ]
            }
        }
        if [postfix_delays] {
            grok {
                patterns_dir   => "/etc/logstash/conf.d/patterns.d"
                match          => ["postfix_delays", "%{POSTFIX_DELAYS}"]
                tag_on_failure => [ "_grok_kv_postfix_delays_nomatch" ]
                remove_field   => [ "postfix_delays" ]
            }
        }
    }

    # Do some data type conversions
    mutate {
        convert => [
            # list of integer fields
            "postfix_anvil_cache_size", "integer",
            "postfix_anvil_conn_count", "integer",
            "postfix_anvil_conn_rate", "integer",
            "postfix_client_port", "integer",
            "postfix_nrcpt", "integer",
            "postfix_postscreen_cache_dropped", "integer",
            "postfix_postscreen_cache_retained", "integer",
            "postfix_postscreen_dnsbl_rank", "integer",
            "postfix_relay_port", "integer",
            "postfix_server_port", "integer",
            "postfix_size", "integer",
            "postfix_status_code", "integer",
            "postfix_termination_signal", "integer",
            "postfix_uid", "integer",

            # list of float fields
            "postfix_delay", "float",
            "postfix_delay_before_qmgr", "float",
            "postfix_delay_conn_setup", "float",
            "postfix_delay_in_qmgr", "float",
            "postfix_delay_transmission", "float",
            "postfix_postscreen_violation_time", "float"
        ]
    }
    }
    }
#-------数据输出段.----------
output {
            elasticsearch{
                    hosts => [ "elasticsearch" ]
                    index => "logstash-%{type}-%{+YYYY.MM.dd}"
                    document_type => "%{type}"
                    flush_size => 500
                    idle_flush_time => 5
            }
            
}

#for debug
#output {
#       stdout{codec => rubydebug}
#}

